{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e31a89",
   "metadata": {},
   "source": [
    "# Versão 07.09.2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf81986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\env_saad\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Leonardo\\AppData\\Local\\Temp\\ipykernel_3772\\2670590639.py\", line 109, in realizar_treinamento\n",
      "    face_encoding = face_recognition.face_encodings(face_image)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\env_saad\\Lib\\site-packages\\face_recognition\\api.py\", line 214, in face_encodings\n",
      "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\envs\\env_saad\\Lib\\site-packages\\face_recognition\\api.py\", line 214, in <listcomp>\n",
      "    return [np.array(face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: compute_face_descriptor(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], face: _dlib_pybind11.full_object_detection, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vector\n",
      "    2. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], num_jitters: int = 0) -> _dlib_pybind11.vector\n",
      "    3. (self: _dlib_pybind11.face_recognition_model_v1, img: numpy.ndarray[(rows,cols,3),numpy.uint8], faces: _dlib_pybind11.full_object_detections, num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectors\n",
      "    4. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], batch_faces: List[_dlib_pybind11.full_object_detections], num_jitters: int = 0, padding: float = 0.25) -> _dlib_pybind11.vectorss\n",
      "    5. (self: _dlib_pybind11.face_recognition_model_v1, batch_img: List[numpy.ndarray[(rows,cols,3),numpy.uint8]], num_jitters: int = 0) -> _dlib_pybind11.vectors\n",
      "\n",
      "Invoked with: <_dlib_pybind11.face_recognition_model_v1 object at 0x000001D8CDECFE70>, array([[[ 17,  17,  17],\n",
      "        [ 20,  20,  20],\n",
      "        [ 25,  25,  25],\n",
      "        ...,\n",
      "        [  5,   5,   5],\n",
      "        [  4,   4,   4],\n",
      "        [  9,   9,   9]],\n",
      "\n",
      "       [[ 16,  16,  16],\n",
      "        [ 20,  20,  20],\n",
      "        [ 25,  25,  25],\n",
      "        ...,\n",
      "        [  6,   6,   6],\n",
      "        [  5,   5,   5],\n",
      "        [ 10,  10,  10]],\n",
      "\n",
      "       [[ 17,  17,  17],\n",
      "        [ 19,  19,  19],\n",
      "        [ 23,  23,  23],\n",
      "        ...,\n",
      "        [  6,   6,   6],\n",
      "        [  3,   3,   3],\n",
      "        [  7,   7,   7]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 48,  48,  48],\n",
      "        [ 76,  76,  76],\n",
      "        [ 88,  88,  88],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 48,  48,  48],\n",
      "        [ 76,  76,  76],\n",
      "        [ 88,  88,  88],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[ 60,  60,  60],\n",
      "        [ 83,  83,  83],\n",
      "        [ 87,  87,  87],\n",
      "        ...,\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255]]], dtype=uint8), <_dlib_pybind11.full_object_detection object at 0x000001D8CD56D270>, 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import face_recognition\n",
    "from sklearn import svm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ReconhecimentoFacialApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Reconhecimento Facial Yale\")\n",
    "\n",
    "        # Centralize a janela principal\n",
    "        window_width = 800\n",
    "        window_height = 600\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        x = (screen_width - window_width) // 2\n",
    "        y = (screen_height - window_height) // 2\n",
    "        self.root.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "        self.root.configure(bg=\"black\")\n",
    "        \n",
    "        self.criar_widgets()\n",
    "\n",
    "    def criar_widgets(self):\n",
    "        self.criar_frame_titulo()\n",
    "        self.criar_frame_botoes()\n",
    "        self.criar_frame_resultado()\n",
    "\n",
    "    def criar_frame_titulo(self):\n",
    "        self.frame_titulo = tk.Frame(self.root, bg=\"black\")\n",
    "        self.frame_titulo.pack(pady=20)\n",
    "        \n",
    "        self.label_titulo = tk.Label(self.frame_titulo, text=\"Sistema de Reconhecimento Facial Yale\", font=(\"Helvetica\", 20), bg=\"black\", fg=\"white\")\n",
    "        self.label_titulo.pack()\n",
    "\n",
    "    def criar_frame_botoes(self):\n",
    "        self.frame_botoes = tk.Frame(self.root, bg=\"black\")\n",
    "        self.frame_botoes.pack()\n",
    "\n",
    "        self.botao_treinamento = tk.Button(self.frame_botoes, text=\"Treinamento\", font=(\"Helvetica\", 18), command=self.realizar_treinamento, bg=\"aquamarine\", fg=\"black\")\n",
    "        self.botao_treinamento.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.botao_validacao_teste = tk.Button(self.frame_botoes, text=\"Validação/Teste\", font=(\"Helvetica\", 18), command=self.realizar_validacao_teste, bg=\"aquamarine\", fg=\"black\")\n",
    "        self.botao_validacao_teste.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "    def criar_frame_resultado(self):\n",
    "        self.frame_resultado = tk.Frame(self.root, bg=\"black\", highlightbackground=\"aquamarine\", highlightthickness=2)\n",
    "        self.frame_resultado.pack(pady=20)\n",
    "        \n",
    "        self.label_imagem_validacao = tk.Label(self.frame_resultado, bg=\"black\", padx=10, pady=10)\n",
    "        self.label_imagem_validacao.pack()\n",
    "\n",
    "        self.label_mensagem_reconhecimento = tk.Label(self.frame_resultado, text=\"\", bg=\"black\", fg=\"white\", font=(\"Helvetica\", 16))\n",
    "        self.label_mensagem_reconhecimento.pack()\n",
    "\n",
    "        self.frame_icones = tk.Frame(self.frame_resultado, bg=\"black\")\n",
    "        self.frame_icones.pack(pady=10)\n",
    "\n",
    "        self.fig, self.ax = plt.subplots()  \n",
    "        self.ax.set_xlabel(\"Treinamento\")\n",
    "        self.ax.set_ylabel(\"Acurácia\")\n",
    "        self.acuracia_data = []\n",
    "\n",
    "    def realizar_treinamento(self):\n",
    "        yale_encodings = []\n",
    "        yale_labels = []\n",
    "        imagens_com_erro = []\n",
    "        total_imagens = 0\n",
    "        imagens_treinadas = 0\n",
    "        dataset_path = 'src/yalefaces'\n",
    "\n",
    "        for subject_folder in os.listdir(dataset_path):\n",
    "            subject_folder_path = os.path.join(dataset_path, subject_folder)\n",
    "            if os.path.isdir(subject_folder_path):\n",
    "                image_count = 0\n",
    "                for img_name in os.listdir(subject_folder_path):\n",
    "                    if img_name.endswith(\".gif\"):\n",
    "                        image_count += 1\n",
    "                        if image_count <= 7:\n",
    "                            total_imagens += 1\n",
    "                            identity = subject_folder\n",
    "                            image = face_recognition.load_image_file(os.path.join(subject_folder_path, img_name))\n",
    "                            \n",
    "                            # Verifique se a imagem está em escala de cinza\n",
    "                            if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "                                # Converta a imagem para tons de cinza\n",
    "                                image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "                            \n",
    "                            # Equalização de histograma\n",
    "                            image = cv2.equalizeHist(image)\n",
    "\n",
    "                            # Converta a imagem de tons de cinza de volta para RGB\n",
    "                            image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "                            # Detecte os rostos na imagem\n",
    "                            face_locations = face_recognition.face_locations(image_rgb)\n",
    "                            if len(face_locations) == 1:\n",
    "                                face_location = face_locations[0]\n",
    "                                top, right, bottom, left = face_location\n",
    "                                face_image = image_rgb[top:bottom, left:right]\n",
    "                                \n",
    "                                # Codifique o rosto\n",
    "                                face_encoding = face_recognition.face_encodings(face_image)\n",
    "                                if len(face_encoding) > 0:\n",
    "                                    yale_encodings.append(face_encoding[0])\n",
    "                                    yale_labels.append(identity)\n",
    "                                    imagens_treinadas += 1\n",
    "                                    print(f\"Face cadastrada: {identity}\")\n",
    "                                else:\n",
    "                                    imagens_com_erro.append(os.path.join(subject_folder_path, img_name))\n",
    "                                    print(f\"Erro na imagem: {os.path.join(subject_folder_path, img_name)}\")\n",
    "                            else:\n",
    "                                imagens_com_erro.append(os.path.join(subject_folder_path, img_name))\n",
    "                                print(f\"Erro na imagem: {os.path.join(subject_folder_path, img_name)}\")\n",
    "        \n",
    "        print(f\"Total de imagens processadas: {total_imagens}\")\n",
    "        print(f\"Total de imagens treinadas: {imagens_treinadas}\")\n",
    "        print(f\"Imagens com erro: {len(imagens_com_erro)}\")\n",
    "        \n",
    "        # Salve as codificações e rótulos em arquivos para uso posterior\n",
    "        np.save('yale_encodings.npy', yale_encodings)\n",
    "        np.save('yale_labels.npy', yale_labels)\n",
    "\n",
    "    def realizar_validacao_teste(self):\n",
    "        image_path = filedialog.askopenfilename(title=\"Selecionar Imagem\", filetypes=[(\"Imagens\", \"*.gif\")])\n",
    "        if image_path:\n",
    "            # Remova o frame de ícones existente e crie um novo\n",
    "            self.frame_icones.destroy()\n",
    "            self.frame_icones = tk.Frame(self.root, bg=\"black\")\n",
    "            self.frame_icones.pack()\n",
    "            self.validar_reconhecimento(image_path)\n",
    "    \n",
    "    def validar_reconhecimento(self, image_path):\n",
    "        if not os.path.exists(\"modelo_classificador.pkl\"):\n",
    "            messagebox.showerror(\"Erro\", \"Modelo não treinado. Realize o treinamento antes de fazer a validação/teste.\")\n",
    "            return\n",
    "\n",
    "        with open(\"modelo_classificador.pkl\", \"rb\") as f:\n",
    "            svm_classifier = pickle.load(f)\n",
    "\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        face_locations = face_recognition.face_locations(image)\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "        if not face_encodings:\n",
    "            #messagebox.showerror(\"Erro\", \"Nenhuma face foi encontrada na imagem.\")\n",
    "            self.label_mensagem_reconhecimento.config(text=\"Pessoa não reconhecida\")\n",
    "            self.mostrar_icone_x()\n",
    "            # Mostrar a imagem original na label\n",
    "            img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(img_rgb)\n",
    "            img_tk = ImageTk.PhotoImage(img_pil)\n",
    "            self.label_imagem_validacao.config(image=img_tk)\n",
    "            self.label_imagem_validacao.image = img_tk\n",
    "            return\n",
    "\n",
    "        predicted_labels = []\n",
    "        for face_encoding in face_encodings:\n",
    "            _label = svm_classifier.predict([face_encoding])\n",
    "            predicted_labels.append(_label[0])\n",
    "\n",
    "        img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img_rgb)\n",
    "        img_tk = ImageTk.PhotoImage(img_pil)\n",
    "        self.label_imagem_validacao.config(image=img_tk)\n",
    "        self.label_imagem_validacao.image = img_tk\n",
    "\n",
    "        predicted_names = \", \".join(predicted_labels)\n",
    "        if predicted_names:\n",
    "            self.label_mensagem_reconhecimento.config(text=f\"Pessoa Reconhecida: {predicted_names}\")\n",
    "            self.mostrar_icone_verificado()\n",
    "        else:\n",
    "            self.label_mensagem_reconhecimento.config(text=\"Pessoa não reconhecida\")\n",
    "            self.mostrar_icone_x()\n",
    "\n",
    "        self.mostrar_resultado_reconhecimento(predicted_names)\n",
    "\n",
    "\n",
    "    def mostrar_resultado_reconhecimento(self, predicted_names):\n",
    "        self.frame_icones.destroy()  # Remover o frame existente\n",
    "\n",
    "        self.frame_icones = tk.Frame(self.frame_resultado, bg=\"black\")\n",
    "        self.frame_icones.pack(pady=10)\n",
    "\n",
    "        if predicted_names:\n",
    "            self.mostrar_icone_verificado()\n",
    "        else:\n",
    "            self.mostrar_icone_x()\n",
    "            \n",
    "\n",
    "    def mostrar_icone_verificado(self):\n",
    "        # Crie e mostre o ícone de verificação\n",
    "        icone_verificado = Image.open(\"icone_verificado.png\")\n",
    "        icone_verificado = icone_verificado.resize((100, 100))\n",
    "        icone_verificado = ImageTk.PhotoImage(icone_verificado)\n",
    "        label_icone = tk.Label(self.frame_icones, image=icone_verificado, bg=\"black\")\n",
    "        label_icone.image = icone_verificado\n",
    "        label_icone.pack()\n",
    "\n",
    "    def mostrar_icone_x(self):\n",
    "        # Crie e mostre o ícone \"X\"\n",
    "        icone_x = Image.open(\"icone_x.png\")\n",
    "        icone_x = icone_x.resize((100, 100))\n",
    "        icone_x = ImageTk.PhotoImage(icone_x)\n",
    "        label_icone = tk.Label(self.frame_icones, image=icone_x, bg=\"black\")\n",
    "        label_icone.image = icone_x\n",
    "        label_icone.pack()\n",
    "\n",
    "\n",
    "    def plot_acuracia(self):\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlabel(\"Treinamento\")\n",
    "        self.ax.set_ylabel(\"Acurácia\")\n",
    "\n",
    "        # Ajuste o tamanho da figura\n",
    "        self.fig.set_size_inches(10, 6)  # Escolha as dimensões desejadas\n",
    "\n",
    "        # Personalize o intervalo do eixo x (por exemplo, de 0 a 100)\n",
    "        self.ax.set_xlim(0, len(self.acuracia_data) + 1)\n",
    "        self.ax.set_xticks(range(0, len(self.acuracia_data) + 1, 10))  # Personalize os intervalos dos ticks se necessário\n",
    "\n",
    "        self.ax.plot(range(1, len(self.acuracia_data) + 1), self.acuracia_data, marker='o')\n",
    "        self.ax.set_ylim([0, 1])\n",
    "        self.ax.grid(True)\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ReconhecimentoFacialApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed06375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
